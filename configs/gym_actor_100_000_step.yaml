n_repetition: 10
env_name : ant
gym_version : v3
actor : '[256,256] actor'
legacy_spring : true
device : ???
torch_device : cuda

jax_model:
  _target_ : jax_rollout.networks.flax_networks.create_MLP
  hidden_sizes : [256,256]
  activation : flax.linen.relu
    # output_activation : flax.linen.relu #  if not specified => identity activation function for the output

pytorch_model:
    _target_ : jax_rollout.networks.pytorch_networks.MLP
    hidden_sizes : [256,256]
    activation : torch.nn.ReLU
      # output_activation : #  if not specified => identity activation function for the output


configurations: 
  [
    # 1-individual tests : 
    # {'n_pop' : 1,   'n_env' : 6250, 'n_step': 16 },
    {'n_pop' : 1,   'n_env' : 500,  'n_step': 200 },
    {'n_pop' : 1,   'n_env' : 100,  'n_step': 1000 },
    # 10-individuals test :
    {'n_pop' : 10,  'n_env' : 50,    'n_step': 200  },
    {'n_pop' : 10,  'n_env' : 10,    'n_step': 1000  },
    # 100-indiviuals test :
    {'n_pop' : 100, 'n_env' : 5,     'n_step': 200  }, 
    {'n_pop' : 100, 'n_env' : 1,     'n_step': 1000  },
  ]
save_filename : mid_actor

# declaration of a methods, a list containing 
# functions wich corresponds to rollout functions to launch
classes : 
  # gym_256_x2 : jax_rollout.with_actors.exp_utils.with_gym_setup
  envpool_256_x2 : jax_rollout.with_actors.exp_utils.with_envpool_sync_setup
